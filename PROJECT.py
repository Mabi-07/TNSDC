# -*- coding: utf-8 -*-
"""workshop1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1stGMDWAe9IAFAQR26OIsTkJUZJgzKmXV
"""

import pandas as pd
data = pd.read_csv('https://raw.githubusercontent.com/mohitgupta-omg/Kaggle-SMS-Spam-Collection-Dataset-/master/spam.csv', encoding='latin-1')
data.head()

data.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'] , axis=1, inplace=True)
data.columns = ['label','text']
data.head()

# text preprocessing
# download nltk
import nltk
nltk.download('all')

# create a list text
text = list(data['text'])
# print(text)
# print(len(text))
# preprocessing loop
import re
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

lemmatizer = WordNetLemmatizer()
corpus = []
for i in range(len(text)):

    r = re.sub('[^a-zA-Z]', ' ', text[i])
    r = r.lower()
    r = r.split()
    r = [word for word in r if word not in stopwords.words('english')]
    r = [lemmatizer.lemmatize(word) for word in r]
    r = ' '.join(r)
    corpus.append(r)

#assign corpus to data['text']
data['text'] = corpus
data.head()

# Create Feature and Label sets

X = data['text']

y = data['label']

# train test split (66% train - 33% test)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=123)
print('Training Data :', X_train.shape)
print('Testing Data : ', X_test.shape)

# Train Bag of Words model

from sklearn.feature_extraction.text import CountVectorizer

cv = CountVectorizer()
X_train_cv = cv.fit_transform(X_train)
X_train_cv.shape
print(cv.get_feature_names_out())
print(X_train_cv.toarray())

# Training Logistic Regression model

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression()
lr.fit(X_train_cv, y_train)

# transform X_test using CV

X_test_cv = cv.transform(X_test)

# generate predictions

predictions = lr.predict(X_test_cv)

predictions

# confusion matrix

import pandas as pd

from sklearn import metrics

df = pd.DataFrame(metrics.confusion_matrix(y_test,predictions), index=['ham','spam'], columns=['ham','spam'])

df

# confusion matrix

import pandas as pd

from sklearn.metrics import accuracy_score,confusion_matrix

df = pd.DataFrame(confusion_matrix(y_test,predictions), index=['ham','spam'], columns=['ham','spam'])
print('Accuracy',accuracy_score(y_test,predictions))
df

text = ["Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat..."]
text = cv.transform(text)
lr.predict(text)

#  pip install gradio

# import gradio as gr
# def predict_label(text):
#     # Transform input text using CountVectorizer
#     text_cv = cv.transform([text])
#     # Generate prediction
#     prediction = lr.predict(text_cv)[0]
#     return "ham" if prediction == 1 else "spam"
# # Gradio Interface
# iface = gr.Interface(
#     fn=predict_label,
#     inputs=gr.Textbox(lines=5, label="Enter your text here"),
#     outputs="text",
#     title="Text Classification",
#     description="This model predicts the label (Positive/Negative) of the given text."
# )
# iface.launch()